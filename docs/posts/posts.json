[
  {
    "path": "posts/2023-02-10-energyexplorerio/",
    "title": "energyexplorer.io",
    "description": "An interactive dashboard to calculate NPV and LCOE of utility-scale front-of-meter solar with battery projects in California.",
    "author": [
      {
        "name": "Thomas Wheeler",
        "url": {}
      }
    ],
    "date": "2023-01-01",
    "categories": [
      "energy-transition",
      "economic-modeling",
      "interactive-data-visualization"
    ],
    "contents": "\n\n\n\n\nProject overview\nenergyexplorer.io is a web application I independently developed to automate parts of a renewable energy project valuation assignment from Dr. Ranjit Deshmukh’s Energy & Electric Power Systems course at the Bren School of Environmental Science & Management.\nThe main goal of the application to provide an intuitive, user-interactive dashboard for renewable energy developers to estimate the levelized cost of energy (LCOE) and net present value (NPV) of a proposed project at a desired location in California.\nTo step through the energy and economic calculations performed by the app’s backend, explore data-pipeline.ipynb in this repo.\nData analysis\nTo calculate LCOE and NPV for a user defined location the application:\nSends user defined project parameters to NREL’s National Solar Radiation Database (NSRDB) which returns a one year historical hourly solar radiation for the project’s latitude & longitude.\nConverts historical hourly solar radiation dataset to hourly energy generation using modules from NREL’s System Advisor Model (SAM)\nIdentifies the the nearest CAISO wholesale LMP Node that the proposed plant could sell electricity to.\nExtracts one year historical hourly LMP prices from nearest LMP node (currently using static dataset due to difficulty connecting to CAISO API) and joins with hourly generation dataset.\nSimulates additional earnings generated through energy arbitrage if user includes a battery with the plant. To simulate arbitrage, the application assumes prices and energy generation will be exactly the same as the prior year. The battery is charged only\n\nDuring hours when the solar plant is generating electricity\nWhen the LMP price for the hour is lower than during evening hours when the plant stops generating\nAnd when there is still charge available in the battery.\n\nCalculates LCOE per MWh is calculated using the following formula:\nlcoe = (((capital_cost_per_mw * (1-tax_credit/100)) * installed_capacity * crf) + (fixed_cost_per_mwh * installed_capacity)) / (installed_capacity * dc_capacity_factor * annual_operating_hours)\nwhere:\n\ncapital_cost_per_mw: total cost of plant construction per MWdc\ntax_credit: 30% ITC\ninstalled_capacity: total installed capacity of plant in MWdc\ncrf: capital recovery factor, a ratio used to determine the present value of a series of equal annual cash payments\nfixed_cost_per_mwh: fixed O&M cost per MWdc to operate the plant over project lifetime\ndc_capacity_factor: capacity factor (the ratio of the electrical energy produced by a generating unit for the period of time considered to the electrical energy that could have been produced at continuous full power operation during the same period. source: EIA)\nannual_operating_hours: total number of hours per year the plant is operational\n\nCalculates NPV by subtracting LCOE per MWh from average plant earnings per MWh and discounting over project lifetime\nGraphs output\nData\nNational Solar Radiation Database (NSRDB)\n- Database of hourly and half-hourly solar radiation (global horizontal, direct normal, and diffuse horizontal irradiance) across the United States and in some international locations. This dataset is accessed using NREL’s Python API.\nNREL’s System Advisor Model (SAM)\n- SAM is a model used to calculate energy generation and financial projections for a variety of renewable energy systems. energyexplorer.io uses SAM’s energy generation model to convert solar radiation data from NSRDB to energy generation by a solar plant with user defined parameters. This tool is accessed using the NREL-PySAM package.\nCAISO OAIS\n- Database of real-time and historical data related to the ISO transmission system and its Market, such as system demand forecasts, transmission outage and capacity status, market prices and market result data. Click here to view a realtime map of wholesale energy prices across California. The current version of energyexplorer.io uses a static, one year hourly dataset from the HOLLISTR_1_N101 for all future price predictions. This dataset was manually extracted using the CAISO OASIS online downloader.\nU.S. Solar Photovoltaic System and Energy Storage Cost Benchmarks: Q1 2021\n- This NREL report was used to define capex and fixed o&m parameters used to calculated the levelized cost of energy (LCOE) in energyexplorer.io. More about cost and performance parameters provided by NREL for electricity generating technologies can be found here.\nNREL’s Cambium Viewer\n- Database and viewing tool developed by NREL to project future wholesale energy prices and marginal emission rates across the United States. Projections provided by Cambium were are not currently used in energyexplorer.io.\nApplication tech stack\nFront-end:\nHTML\nCSS\nJavaScript (datatables.js, leaflet.js, intro.js)\nBack-end:\nDjango\nPython (pandas, numpy)\n\n\n\n",
    "preview": "posts/2023-02-10-energyexplorerio/solar_farm.svg",
    "last_modified": "2023-04-03T17:52:31-07:00",
    "input_file": "energyexplorerio.knit.md"
  },
  {
    "path": "posts/2023-02-21-movingbitsorg/",
    "title": "movingbits.org",
    "description": "An interactive dashboard to visualize publicly reported data center energy use and sustainability reporting transparency trends from 50+ of the largest global technology companies.",
    "author": [
      {
        "name": "Thomas Wheeler",
        "url": {}
      }
    ],
    "date": "2022-09-24",
    "categories": [
      "energy-demand",
      "energy-transition",
      "interactive-data-visualization"
    ],
    "contents": "\n\nNOTE: Site is scheduled for launch this summer, link\nis not yet live. Contact me for a demo of test server.\nProject overview\nIn recent years, demand for computing power has emerged as a\nsignificant industrial energy consumer, attracting the interest of\nclimate modelers/policymakers, corporate sustainability leaders, and the\npublic as an area of our energy system needing better data to estimate\nits current and future energy consumption.\nEfforts to model the energy use of this sector have traditionally\nrelied on using indirect methods (ex. finding data on the number of\nservers shipped from country A to country B and assuming those servers\nwould be used X percent of the time at X capacity) due to opaqueness in\nsustainability report by large computing energy users and the relatively\ndistributed nature of the internet’s energy use.\nThe rise of large technology companies (Amazon, Apple, Google, etc.),\nwho’ve invested heavily in providing computing services, since the\nmid-2000s has shifted this dynamic in two key ways:\nA greater percentage of the internet’s total energy use is\nshifting from on-site, small-scale servers managed by in-house IT teams\nto off-site, large-scale, remotely managed data centers. The largest of\nthese data centers are warehouses filled with thousands of servers that\nprovide computing power to a multitude of users, generally via internet\nconnection. These data centers are operated by a relatively small number\nof large technology companies and are growing at a rapid pace,\naccounting for an estimated\n89% of compute instances in 2018.\nNotably though, data center energy demand per compute instance has decreased\nannually by 20% since 2010 demonstrating the potential for\nlarge-scale data centers to offset some of the total energy demand\nthrough efficiency gains. As this relatively small group of companies\nuses more and more of total computing energy demand, we will become more\nreliant on their transparency to get closer to finding an aggregate\nnumber for total global computing energy demand.\nIncreasing public concern about the social and environmental\nimpact of large technology firms have put pressure on these companies to\nbe more transparent about their energy use and emissions. As companies\nare more transparent in their reporting, the public will be able to put\ntogether the larger puzzle of total current and future energy\ndemand.\nUltimately, to find an aggregate “total energy use of the internet”\nvalue, a mix of data center operator reported statistics & indirect\nmethods will likely be needed. To unlock the value of this data,\ncompanies will need to move toward reporting data center energy\nconsumption and other sustainability data (energy efficiency, emissions,\netc.) publicly using a standardized, easily accessible, and\npublicly-available methodology. As of this writing in 2022,\npublicly available reporting of data center energy use and related\nsustainability data is largely non-standardized, consisting primarily of\na mix of self-reported statistics released in CSR/ESG reports, websites,\nfinancial filing, and news articles. For many companies, aggregate\nenergy reporting is non-existent.\nOur purpose\nmovingbits.org aims to fill the absence of widely available, easy to\naggregate and visualize data center energy use and sustainability data.\nOur application aims to:\nBe an educational resource for members of the public who are\ninterested in learning more about how data centers work and their energy\ndemand.\nProvide accurate, up to date statistics on individual company and\nindustry-wide energy use and transparency trends.\nIndirectly put pressure on companies who are lagging in energy\nreporting transparency or falling behind on reaching sustainability\ngoals.\nData\nThe dataset visualized by the dashboard is a compilation of energy,\nsustainability, and reporting transparency data from 50+ of the largest\nglobal technology companies.\nData is currently collected and input manually into a central\ndatabase by the movingbits.org team. Reporting sources for each company\ncan be found on the “Single Company Analysis” tab.\nSome examples of places where we collect data from include:\nAnnual report (ex. Twitter\nFY2020 Annual Report)\nWeb page (ex. Microsoft\n- How Microsoft measures datacenter water and energy use to improve\nAzure Cloud sustainability)\nSEC Filing (ex. Digital\nRealty 10K)\nSustainability Report (ex. Apple\n2021 Environmental Progress Report)\nApplication tech stack\nFront-end:\nHTML\nCSS\nJavaScript\nBack-end:\nR Shiny\nR\n\n\n\n",
    "preview": "posts/2023-02-21-movingbitsorg/moving-bits-logo-no-line-dark-bg.svg",
    "last_modified": "2023-02-24T16:35:38-08:00",
    "input_file": {}
  },
  {
    "path": "posts/2023-02-24-energydemand/",
    "title": "Assessing a Low Energy and Emissions Pathway for Commercial Buildings from 2022 - 2050",
    "description": "An analysis of the projected change in energy demand and emissions from commercial buildings by implementing efficiency standards, financial incentives for new technologies, and building code updates.",
    "author": [
      {
        "name": "Thomas Wheeler",
        "url": {}
      }
    ],
    "date": "2022-05-19",
    "categories": [
      "energy-demand",
      "energy-transition",
      "energy-modeling",
      "data-visualization"
    ],
    "contents": "\n\nProject overview\nThis analysis was conducted as the final project for Professor Eric Masanet’s Energy Demand Analysis course taught at the Bren School of Environmental Science & Management. The goal of this project was to assess to what degree energy demand reduction strategies can contribute to decarbonizing commercial buildings by 2050.\nTo answer this question, my team and I modeled primary energy demand and emissions from 2022 - 2050 under 2 scenarios:\nA baseline scenario where no energy demand reduction strategies are implemented.\nA low energy & emissions (LEES) scenario where efficiency standards, financial incentives for new technologies, and building code updates are implemented.\n*both scenarios assume the electric grid mix (percentage of energy coming from zero carbon sources) is significantly less carbon intensive by 2050.\nModel Development Steps\nOur model development consisted of 6 steps:\n1. Determine what energy services and the respective technologies providing these services to include in modeling scope. We chose to model energy change and emissions for:\nExamples of energy services.Space heating (district heating, electric heat pump, natural gas furnace, natural gas boiler)\nSpace cooling (electric air conditioner, electric chiller)\nWater heating (natural gas tankless, electric tankless, heat pump)\nDish washing (dishwasher)\nLightining (incandescent bulbs, fluorescent bulbs, LED bulbs)\nPersonal computing (desktop computer, laptop computer, monitor)\nRefrigeration (refrigerator)\nNOTE: the energy service is the service being demanded by the energy user from the technology. For example, lighting is the energy service demanded from the energy user by a light bulb. Energy technologies are listed above in parenthesis next to their respective energy service.\n2. Divide analysis for each scenario into separate excel models for easier usability:\nBaseline scenario for space heating and cooling (note: geographic region inputs & outputs are contained in separate sheets)\nLEES scenario for space heating and cooling (note: geographic region inputs & outputs are contained in separate sheets)\nBaseline & LEES scenarios for water heating, appliances, lighting, personal computing, refrigeration (WALPR) (note: baseline inputs and outputs are on sheet 1 & 2, respectively. LEES inputs and outputs are on sheets 3 & 4, respectively.)\n3. Calculate future demand for energy services in commercial buildings:\nCalculations for projected total commmercial building floor area.Begin by calculating projected total commercial building floor area (in ft2) for Northeast, Midwest, South, and West EIA census divisions using projections using EIA CBECS data. Copy these regional floor area projections across each model.\nWithin the space heating and cooling models, account for variability in demand for heating and cooling across each region by calculating projected heating degree days (HDD) and cooling degree days (CDD). These are measure of the demand for space heating and cooling by buildings based on the ambient outdoor temperature.*\nWithin the WALPR model, make the following assumptions:\nenergy demand for each ft2 of future commercial buildings will remain constant\naverage floor area per worker will not change\nenergy demand does not vary by geography (no need to account for HDD and CDD) and is equally distributed by region across the U.S.\nthe number of commercial building workers will grow in proportion to the ft2 of the building\nIn short, the density of future workers in commercial buildings will stay the same, energy intensity per worker in a commercial buildings will stay the same, and each worker will use the same amount of energy on average all around the United States.\n*The number of heating/cooling degree days for each region are calculated by (1) calculating the mean temperature of a day (daily high + daily low/2) and subtracting by 65F (2) repeating this calculation for all days in 1 year and then summing. Click here for a more detailed explanation. We assume, due to climate change leading to generally warmer temperatures year round, the number of heating degree days will have a CAGR of -0.5% and cooling degree days will have a CAGR of 0.7% across each region.\n4. Model energy demand and emissions for the baseline models:\nWith no demand-side technology or behavioral changes, the baseline scenario makes the following assumptions:\nChange in GHG emissions for space heating and cooling under baseline scenario.Change in primary energy for space heating and cooling under baseline scenario.Baseline space heating and cooling model:\nEnergy demand for all technologies will increase due to the increase in total amount of commercial building floor area (ft2) and thus more floor area needing heating and cooling\nHeat pumps will experience efficiency gains through time, while other technology’s energy efficiency will not change due to their relative maturity\nAdoption of energy technologies for air heating and cooling will remain constant to 2050 at 2022 percentages (77% demand met by natural gas, 4% demand met by electricity, 19% met by district heating)\nNo reduction in individual user energy usage through behavior change\nChange in GHG emissions for WALPR under baseline scenario.Change in primary energy for WALPR under baseline scenario.Baseline WALPR model:\nEnergy demand for all technologies will increase due to an increased number of workers in commercial buildings\nAdoption of energy technologies for WALPR will remain constant to 2050 at 2022 percentages (e.g. for lighting, 12% of lumens met by incandescent bulbs, 58% of lumens met by fluorescent bulbs, 30% of lumens met by LEDs)\nNo efficiency changes for water heaters, appliances, light bulbs, personal computers, or refrigerators\nNo reduction in individual user energy usage through behavior change\n5. Choose what energy demand reduction strategies to model in the LEES scenario:\nWe chose the following strategies for reducing energy demand:\n💡📈 Increase share of LED lighting via a government subsidy (direct payment) on LED purchases.\n💡📉 Phase out low efficiency lighting (incandescent lighting) by instituting a ban on light bulbs that producing less than 45 lumens per watt by 2030.\n⚡️🌬📈 Increase share of heat pumps for air heating/cooling with a subsidy (tax credit) for new heat pump purchases.\n⚡♨️📈 Increase share of heat pumps for water heating/cooling with a subsidy (tax credit) for new heat pump purchases.\n💻📈 Increase adoption of Energy Star appliances (computer, dishwasher, refrigerator) by mandating minimum efficiency standards for appliances.\n🌱👷📈Increase share of “green construction” (daylighting, green walls, white paint on roofs) used in newly constructed buildings with a financial incentive for green construction.\n🌱👷📈Increase insulation used in new building construction and retrofits by updating building code requirements.\n⚙️🌬Optimize air heating and cooling with NEST thermostat with a subsidy (direct payment) for NEST thermostat installations.\n6. Model energy demand and emissions for the LEES models:\n\nCalculate the projected energy demand and emissions under the LEES scenario by projecting the energy change due to:\nFuel Switching — reducing demand for energy or emissions intensity by switching from a high energy/emissions intensity technology to low energy energy/emissions intensity technology (i.e. replacing natural gas furnace with heat pump)\nDemand Avoidance — reducing demand for energy in the first place (i.e. demand reduction from better building design or NEST thermostat installation)\nEnergy Efficiency — energy demand reduction induced via modeled technologies become more energy efficient through time (i.e. a personal computer using less energy per unit)\nGraphing and interpreting results\nChange in GHG emissions for WALPR under LEES scenario.Change in primary energy for WALPR under LEES scenario.Change in GHG emissions for space heating and cooling under LEES scenario.Change in primary energy for space heating and cooling under LEES scenario.Results\nFor the heating and cooling model, the proposed LEES scenario policies pushed primary energy demand down to 687.5 PJ by 2050 (down from 1,011 PJ in 2022). This constitutes a 33.3% reduction relative to our baseline scenario. CO2 emissions from heating and cooling decreased from 47.5 MT CO2e in 2022 to 16.3 MT CO2e by 2050. This constitutes a 52% reduction relative to our baseline scenario.\nFor the WALPR model, our proposed policies pushed primary energy demand down to 422 PJ by 2050 from 751 PJ in 2022, a 50% reduction relative to our baseline scenario. CO2 emissions from appliances decreased from 33.16 MT CO2e in 2022 to 8.42 MT CO2e by 2050, a 50% reduction relative to our baseline scenario.\nKey takeaways & insights\nThe most important strategy we found was electrifying heating and cooling, especially through the use of heat pumps. Converting these systems to electricity yields better GHG reductions over time as the grid becomes less carbon intensive. Furthermore, since heat pumps are much more efficient than traditional heating and cooling systems, companies could face significantly less spending on energy given electricity prices stay relatively stable or decrease through 2050. We think that providing a financial incentive for heat pumps adoption, like an upfront cost subsidy, would alleviate high switching costs and other current barriers to adoption.\nSimilarly, switching to LEDs on the appliance side and phasing out the sale of incandescent bulbs by 2030 accounts for a reduction of almost 10 MT CO2e emissions and 200 PJ of primary energy use. We think this is a reasonable goal given the short turnover time of lightbulbs, technological improvements in the quality of LEDs, LED lifespan, and overall energy efficiency gains. Primary energy use of LEDs increases with more use of LEDs, but overall GHG emissions stay near constant, even with the substitution of fluorescent and incandescent bulbs. This can be attributed to a more decarbonized grid with more renewable energy penetration.\nDaylighting, green walls, and white painted roofs are all helpful policies, but they become less important as the electricity grid becomes more decarbonized and appliances and heating and cooling systems become more electrified. Thus, the first goal should be to electrify heating and cooling systems, and the second goal should be to transition to LEDs and phase out incandescent bulbs as quickly as possible.\nExcel Analysis Models\nBaseline Heating & Cooling\nLEES Heating & Cooling\nAppliances (includes both baseline & LEES)\nOther project materials\nFinal report & presentation\nA detailed description of our analysis result can be read in our final report.\nA summary of results can be viewed in our final presentation.\nData\nEPA Office of Air and Radiation, Climate Protection Partnerships Division. Light Bulb Revolution: EPA Predicts Widespread\nConsumer Adoption of LED Lighting by 2020 if Utility Programs Persist. U.S. EPA, 2017.\nhttps://www.energystar.gov/sites/default/files/asset/document/LBR_2017-LED-Takeover.pdf\nIEA (2018), The Future of Cooling; Preti and Caldeira (2015)\nEnergy STAR. 2022. “ENERGY STAR Certified Commercial Water Heaters.” Energy STAR. 2022.\nhttps://www.energystar.gov/productfinder/product/certified-commercial-water-heaters/results.\nEnergy STAR. n.d. “About Energy Efficiency.” Energy STAR. Accessed June 6, 2022.\nhttps://www.energystar.gov/about/about_energy_efficiency.\nOAR US EPA, “Using Green Roofs to Reduce Heat Islands,” Overviews and Factsheets, last modified June 17, 2014, accessed\nJune 1, 2022, https://www.epa.gov/heatislands/using-green-roofs-reduce-heat-islands.\nOAR US EPA, “Using Cool Roofs to Reduce Heat Islands,” Overviews and Factsheets, last modified June 17, 2014, accessed\nJune 1, 2022, https://www.epa.gov/heatislands/using-cool-roofs-reduce-heat-islands.\nBiswas, Kaushik, Som S. Shrestha, Mahabir S. Bhandari, and Andre O. Desjarlais. 2016. “Insulation Materials for Commercial\nBuildings in North America: An Assessment of Lifetime Energy and Environmental Impacts.” Energy and Buildings 112 (January):\n256–69. https://doi.org/10.1016/j.enbuild.2015.12.013.\nU.S. Department of Energy. 2022. Enforcement Policy Statement-General Service Lamps.\nIEA (2021), Lighting, IEA, Paris. https://www.iea.org/reports/lighting\nEPA Office of Air and Radiation, Climate Protection Partnerships Division. Light Bulb Revolution: EPA Predicts Widespread\nConsumer Adoption of LED Lighting by 2020 if Utility Programs Persist. U.S. EPA, 2017.\nhttps://www.energystar.gov/sites/default/files/asset/document/LBR_2017-LED-Takeover.pdf\nDunsky Energy Consulting. 2021. “Heating Electrification: Policies to Drive Ground-Source Heat Pump Adoption.” Heating,\nRefrigeration and Air Conditioning Institute of Canada (HRAI).\nOffice of Energy Efficiency and Renewable Energy. n.d. “Energy Efficiency Policies and Programs.” Energy.Gov. Accessed June\n6, 2022. https://www.energy.gov/eere/slsc/energy-efficiency-policies-and-programs.\nEPA Office of Air and Radiation, Climate Protection Partnerships Division. Light Bulb Revolution: EPA Predicts Widespread\nConsumer Adoption of LED Lighting by 2020 if Utility Programs Persist. U.S. EPA, 2017.\nhttps://www.energystar.gov/sites/default/files/asset/document/LBR_2017-LED-Takeover.pdf\nEPA Office of Air and Radiation, Climate Protection Partnerships Division. Light Bulb Revolution: EPA Predicts Widespread\nConsumer Adoption of LED Lighting by 2020 if Utility Programs Persist. U.S. EPA, 2017.\nhttps://www.energystar.gov/sites/default/files/asset/document/LBR_2017-LED-Takeover.pdf\nGoodman Air Conditioning and Heating. n.d. “Generations of Heat Pumps.” Accessed June 6, 2022.\nhttps://www.goodmanmfg.com/resources/hvac-learning-center/?param1=before-you-buy&param2=what-generation-is-your-h\neat-pump.\nThomas A Deetjen et al 2021 Environ. Res. Lett. 16 084024. https://iopscience.iop.org/article/10.1088/1748-9326/ac10dc\nChua, K. J., S. K. Chou, and W. M. Yang. 2010. “Advances in Heat Pump Systems: A Review.” Applied Energy 87 (12): 3611–24.\nhttps://doi.org/10.1016/j.apenergy.2010.06.014.\nIEA (2019), District heating needs flexibility to navigate the energy transition, IEA, Paris\nhttps://www.iea.org/commentaries/district-heating-needs-flexibility-to-navigate-the-energy-transition\nOverview of Energy Demand Analysis course from syllabus\n“This course will introduce students to basic concepts and quantitative approaches for understanding and analyzing societal demand for energy. In the first half of the course, students will learn core energy analysis skills and principles including working with official energy statistics, quantification of energy services, projecting demand drivers, modeling technology stock turnover, embodied energy accounting, and constructing marginal abatement/cost curves.\nIn the second half of the course, students will apply this knowledge to construct a simplified (i.e., reduced scope) energy demand model for the United States, focusing on the buildings, transport, industrial, and food sectors. Students will also learn about major technological, behavioral, and policy strategies for transforming energy demand as a means of achieving climate objectives, and will apply their models in group projects to develop demand-sides scenarios and plans for deep decarbonization of the U.S. energy system.”\n\n\n\n",
    "preview": "posts/2023-02-24-energydemand/buildings.jpeg",
    "last_modified": "2023-03-29T17:01:04-07:00",
    "input_file": "energydemand.knit.md"
  },
  {
    "path": "posts/2023-03-10-groupproject/",
    "title": "Master's Group Consulting Project",
    "description": "Assessing the Value of Environmental Information for Shellfish Aquaculture Farmers in British Columbia",
    "author": [
      {
        "name": "Thomas Wheeler",
        "url": {}
      }
    ],
    "date": "2022-03-17",
    "categories": [
      "economic-modeling",
      "consulting"
    ],
    "contents": "\nGroup project team members\nThomas Wheeler (project manager)Halley McVeighMariano VizCaitie RezaEmiliano Espinoza\nFaculty advisor\nDr. Christopher Costello\nClient\nScoot Science\nKey documents and links\nFinal reportExecutive summaryFinal presentationFaculty review presentation\nWhat are group projects?\nMaster’s Group Projects bring together teams of 4-5 students to solve environmental problems for a client. As project manager of my group, I served as primary client contact, facilitated team meetings, collaborated on project tasks, and directed project development from initial proposal to final deliverables. Learn more about group projects at the Bren school here.\nFigure 2: Locations of shellfish facilities in 2020. Upper right inset is Baynes Sound.Summary of project\nShellfish aquaculture will play a critical role in meeting the growing global demand for protein with low ecosystem impact and carbon intensity. Regions that have experienced inhibited growth in their shellfish aquaculture industries, such as British Columbia, must invest in technical and community-driven solutions to overcome industry barriers. A key barrier to B.C.’s growth is environmental uncertainty, which impedes optimal farm management and increases the investment risk of shellfish farms.\nTo reduce environmental uncertainty, shellfish operations around the world are investing in environmental monitoring and forecasting technologies to provide environmental information for farmers. These investments may signal that shellfish farmers value environmental information, but no efforts have been made to assess this value. We developed a model to quantify the value of environmental information for shellfish farmers and their decision-making.\nTo develop a holistic understanding of industry obstacles, we also explored the impact of non-environmental barriers on B.C. shellfish farmers. We conducted this evaluation with a literature review and interviews with shellfish farmers, researchers, First Nations members, and industry affiliates. From this research we assessed experiences within three categories of non-environmental barriers and used feature stories to provide grounded examples of farmer experiences.\nFindings from the Value of Environmental Information Model\nOur value of information model showed that perfect knowledge of future average temperature, chlorophyll a. concentration, current speed, and particulate organic matter concentration has value for shellfish aquaculture farmers seeking to optimize their stocking density to maximize expected profit. Further, we found the value of this environmental information is not uniform across these four variables; current speed exhibited the highest value of information and temperature the lowest.\nThe change of the value of information across the four variables was dependent on both the variability of optimal stocking densities and the variability in expected profits across the five model environmental scenarios. Ultimately, this model provided insight into what makes information valuable.\nFigure 2: Farmer decision-making with perfect and uncertain future environmental information for all four environmental variables, each with five possible scenarios with equal probability of occurring in the future. The farmer with perfect information would choose optimal stocking densities under each of the five possible scenarios for each environmental variable while the farmer with uncertain information would choose the stocking density that yielded the highest expected profit on average.Findings from the Assessment of Non-Environmental Barriers\nWe categorized non-environmental barriers into three buckets: regulatory & political, social & cultural, and logistic & economic. Though distinctly divided, many of these barriers are acutely interconnected and carry more or less weight depending on the size of the farm and community in which it’s located. Transportation costs, for example, disproportionately affect remote farms with limited access to processing infrastructure.\nMany social barriers stem from conflicting community priorities, disparities in First Nations involvement in the B.C. industry, and an overall lack of cross-community collaboration. We found that potential solutions to overcoming non-environmental barriers include a shift toward cooperative style business models, investing in First Nation capacity to support new ventures, and forging partnerships to enable community support.\nFigure 3: Team members Tom Wheeler and Caitie Reza interview Dr. Tim Green, a researcher at the Deep Bay Marine Field Station in Baynes Sound. Photo credit: Halley McVeigh.Research Impact\nImproving decision-making under environmental uncertainty and addressing non-environmental industry barriers are crucial steps to foster growth and expand First Nation leadership in the B.C. shellfish industry. Our framework is a tool that environmental forecasting service providers can use to assess what information is most valuable when seeking to reduce environmental uncertainty. Most importantly, this tool provides insight into what factors make information valuable, enabling a more rapid assessment of what environmental information has the greatest potential to impact farmer decision-making.\nInsights from our assessment of non-environmental barriers contribute to a deeper understanding of the B.C. industry landscape and provide a framework for understanding the challenges and experiences of shellfish farmers. To overcome all industry barriers, a combination of new technologies, investments, partnerships, leadership, and increased understanding will be needed to advance the B.C. shellfish industry’s potential.\n\n\n\n",
    "preview": "posts/2023-03-10-groupproject/scoot-logo.jpeg",
    "last_modified": "2023-03-14T10:50:55-07:00",
    "input_file": "groupproject.knit.md"
  },
  {
    "path": "posts/2021-03-13-post3/",
    "title": "Binary logistic regression to test feasibility of using plant characteristic variables to classify whether a palmetto is species Serenoa repens or Sabal etonia.",
    "description": "This document explores differences between two species of *Serenoa* using the variables height, weight, length, number of green leaves.",
    "author": [
      {
        "name": "Thomas Wheeler",
        "url": {}
      }
    ],
    "date": "2021-03-12",
    "categories": [
      "statistical-analysis",
      "data-visualization"
    ],
    "contents": "\nOverview\nThis document explores differences between two species of Serenoa using the variables height, weight, length, number of green leaves. The first section, “Preliminary Data Exploration”, presents 3 visualizations (scatterplot, boxplot, jitterplot) of plant characteristics and how they compare within and between the two species. The second section generates a binomial logistic regression model using plant height, canopy length, canopy width and green leaves as predictor variables to predict differences between these two species. The final section evaluates the success of this model, displaying discrepancies between when the model was correct and incorrect for both species.\nSerenoa repens | Credit: Botanics Wholesale (link: http://www.botanics.com/2018/09/26/serenoa-repens/)Serenoa etonia | Credit: Wikipedia (link: https://en.wikipedia.org/wiki/Sabal_etonia#/media/File:Sabal_etonia.jpg)Data Explained\nThis dataset contains plant characteristics for Serenoa repens and Sabal etonia, at Archbold Biological Station in south-central Florida. Data was collected from 1981 - 2017 in ongoing 5 year intervals.\nRead and Wrangle Data\n\n\nhide\n\n#read in csv data\npalmetto_data <- read_csv(here(\"_posts\", \"post_data\", \"all_palmetto_data.csv\")) %>% \n  select(species, height, length, width, green_lvs) %>%  # select only columns to be used for analysis\n  mutate(species_name = case_when(\n    species == 1 ~ \"Serenoa repens\",\n    species == 2 ~ \"Sabal etonia\"\n  ))\n\n\nPreliminary Data Exploration\n1. Height vs. Length Scatterplot\n\n\nhide\n\nggplot(data = palmetto_data, aes(x = height, y=length)) +\n  geom_point(aes(color=species_name)) +\n  labs(\n    title = 'Height vs. length for Sabla etonia and Serenoa repens (1981-2017)',\n    x = 'Height (cm)',\n    y = 'Length (cm)'\n  )\n\n\n\nFigure 1: This scatter plot explores displays the relationship between length (cm) and height (cm) for Sabal etonia and Serenoa repens.\nKey Takeaway: Height and length for both plants have a strong linear positively correlation. Across the dataset, Sabal etonia appears to be longer and taller than Serenoa repens.\n2. Boxplots comparing counts of green leaves by species\n\n\nhide\n\nggplot(data = palmetto_data, aes(x = species_name, y=green_lvs, fill=species_name)) +\n  geom_boxplot() +\n  scale_fill_brewer(palette = \"Blues\") +\n  labs(\n    title = 'Green leaf count vs. species for Sabla etonia and Serenoa repens (1981-2017)',\n    x = 'Species',\n    y = 'Number of Green Leaves (count)'\n  )\n\n\n\nFigure 2: These boxplots compare the difference in number of green leaves counted for Sabal etonia and Serenoa repens.\nKey Takeaway: Serenoa repens has a higher mean number of green leaves counted than Sabal etonia.\n3. Boxplots comparing counts of green leaves by species\n\n\nhide\n\nggplot(data = palmetto_data, aes(x = species_name, y = width)) +\n  geom_jitter(aes(color=species_name)) +\n  labs(\n    title = 'Green leaf count vs. species for Sabla etonia and Serenoa repens (1981-2017)',\n    x = 'Species',\n    y = 'Width (cm)'\n  )\n\n\n\nFigure 3: These jitterplots compare the difference in width (cm) for Sabal etonia and Serenoa repens.\nKey Takeaway: Serenoa repens and Sabal etonia generally have similar widths.\nBinomial logistic regression model\n\n\nhide\n\n# convert species value to factor\npalmetto_factor <- palmetto_data %>% \n  mutate(species = factor(palmetto_data$species_name)) \n\n#levels(palmetto_factor$species) #check that species was converted to a factor\n\n#create blr model predicting species\npalmetto_blr <- glm(species ~ height + length + width + green_lvs, \n                            data = palmetto_factor, \n                            family = \"binomial\")\n\n# tidydata\npalmetto_tidy <- tidy(palmetto_blr) %>% \n  mutate(p.value = case_when(\n            p.value < .05 ~ \"< .05\")) %>% \n  mutate(term = case_when(\n         term == \"height\" ~ \"Height\",\n         term == \"width\" ~ \"Width\", \n         term == \"length\" ~ \"Length\",\n         term == \"green_lvs\" ~ \"Green leaf count\")) \n\n#create table with model outputs using Kable\nkbl(palmetto_tidy, caption = \"Palmetto Binomial Regression Coefficient Outputs\", col.names = c(\"Variable\", \"Coefficient\", \"Standard Error\", \"Z-statistic\", \"P-value\")) %>%\n  kable_styling(bootstrap_options = \"striped\",\n                full_width = F)\n\n\nTable 1: Palmetto Binomial Regression Coefficient Outputs\n\n\nVariable\n\n\nCoefficient\n\n\nStandard Error\n\n\nZ-statistic\n\n\nP-value\n\n\nNA\n\n\n-3.2266851\n\n\n0.1420708\n\n\n-22.71180\n\n\n< .05\n\n\nHeight\n\n\n0.0292173\n\n\n0.0023061\n\n\n12.66984\n\n\n< .05\n\n\nLength\n\n\n-0.0458233\n\n\n0.0018661\n\n\n-24.55600\n\n\n< .05\n\n\nWidth\n\n\n-0.0394434\n\n\n0.0021000\n\n\n-18.78227\n\n\n< .05\n\n\nGreen leaf count\n\n\n1.9084747\n\n\n0.0388634\n\n\n49.10728\n\n\n< .05\n\n\nBreakdown of model accuracy\n\n\nhide\n\n#make predictions using blr model\nblr_fitted <- palmetto_blr %>%\n  broom::augment(type.predict = \"response\")\n\n#create table of correct vs. incorrect values\nblr_per_correct <- blr_fitted %>% \n  mutate(predicted = case_when(.fitted >= 0.5 ~ 'Serenoa repens', \n                              .fitted < 0.5  ~ 'Sabal etonia')) %>% \n  mutate(accuracy = case_when(predicted == species ~ 'correct', \n                              predicted != species  ~ 'incorrect')) %>% \n  group_by(species, accuracy) %>% \n  summarize(count = n()) %>% \n  pivot_wider(names_from = accuracy,\n              values_from = count) %>% \n  mutate(percent_correct = percent((correct/(correct + incorrect))))\n\nkbl(blr_per_correct, caption = \"Palmetto Binomial Regression Model Accuracy\", \n    col.names = c(\"Species\", \"Number Correct\", \"Number Incorrect\", \"Percent Correct\")) %>%\n    kable_styling(bootstrap_options = \"striped\", full_width = F)\n\n\nTable 2: Palmetto Binomial Regression Model Accuracy\n\n\nSpecies\n\n\nNumber Correct\n\n\nNumber Incorrect\n\n\nPercent Correct\n\n\nSabal etonia\n\n\n5701\n\n\n454\n\n\n93%\n\n\nSerenoa repens\n\n\n5548\n\n\n564\n\n\n91%\n\n\nCitation\nAbrahamson, W.G. 2019. Survival, growth and biomass estimates of two dominant palmetto species of south-central Florida from 1981 - 2017, ongoing at 5-year intervals ver 1. Environmental Data Initiative. https://doi.org/10.6073/pasta/f2f96ec76fbbd4b9db431c79a770c4d5 (Accessed 2021-02-07).\n\n\n\n",
    "preview": "posts/2021-03-13-post3/post3_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2023-03-10T11:39:05-08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-03-13-post2/",
    "title": "Exploratory report of mountain yellow-legged frog (Rana muscosa) abundance data recorded by the Sierra Lakes Inventory Project",
    "description": "This report provides an exploratory overview of mountain yellow-legged frog (Rana muscosa) abundance recorded by the Sierra Lakes Inventory Project (SLIP) from 1995-2002.",
    "author": [
      {
        "name": "Thomas Wheeler",
        "url": {}
      }
    ],
    "date": "2021-03-07",
    "categories": [
      "data-visualization"
    ],
    "contents": "\nOverview\nThis report provides an exploratory overview of mountain\nyellow-legged frog (Rana muscosa) abundance recorded by the Sierra Lakes\nInventory Project (SLIP) from 1995-2002. The original objective of SLIP\nwas to describe impacts of non-native fish on lake communities, but SLIP\ndata has subsequently enabled study of additional ecological issues,\nincluding regional amphibian declines and their impacts on communities,\nand impacts of non-native fish on terrestrial species. In addition,\nthese data are being used to develop fish removal efforts to restore\naquatic ecosystems and recover endangered amphibians.\n\nData\nThis data describes the physical characteristics of and surveyed\naquatic communities for > 8,000 lentic water bodies in the southern\nSierra Nevada, including lakes, ponds, marshes, and meadows. The SLIP\ndata is stored in a relational database that collectively describes\nwater bodies (e.g., depth, elevation, location), surveys (conditions,\neffort), and communities (including approximately 170 fish, amphibian,\nreptile, benthic macroinvertebrate, and zooplankton taxa).\n\n\nhide\n\nknitr::opts_chunk$set(echo = TRUE)\n\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(here)\n\nlibrary(patchwork) #building compound figures\nlibrary(readxl) #read in excel documents\nlibrary(lubridate) #convert dates to R readable\n\n\n\n\n\nhide\n\n#Wrangle data to extract mountain yellow-legged frog (Rana muscosa) count each year across all water bodies\nsierra_amphibians <- read_excel(here(\"_posts\", \"post_data\", \"sierra_amphibians.xlsx\")) %>% #read in amphibian excel file\n  filter(amphibian_species == \"RAMU\") %>% #filter by RAMU\n  mutate(survey_date = ymd(survey_date)) %>% #convert survey date column to an R readable date formate\n  mutate(record_year = year(survey_date)) %>% #extract only year value and put in new coluumn record_year\n  filter(amphibian_life_stage != \"EggMass\") %>% #filter our EggMass values\n  group_by(record_year, amphibian_life_stage) %>% #group by year then amphibian lifestage to get values for each life stage by year\n  count() # get counts for each, put into column \"n\"\n\n#Graph mountain yellow-legged frog (Rana muscosa) count each year across all water bodies\ngraph_1 <- ggplot(data = sierra_amphibians, mapping = aes(x = record_year, y = n, group = amphibian_life_stage)) +\n  geom_line(aes(color = amphibian_life_stage), show.legend = FALSE) +\n  labs(\n    title = \"Counts of mountain yellow-legged frog count each year across all water bodies by life stage\",\n    y = \"Count of amphibian\",\n    x = \"Year\") +\n  geom_label(label=\"Tadpole\", x=1998, y=375, color = \"black\", size=3) +\n  geom_label(label=\"Adult\", x=1998, y=275, color = \"black\", size=3) +\n  geom_label(label=\"SubAdult\", x=1998, y=175, color = \"black\", size=3) +\n  theme_minimal()\n\n\n\n\n\nhide\n\n#Wrangle combined adult and subadult endangered mountain yellow-legged frogs (Rana muscosa) observed in the 5 lakes with the greatest total observed counts\nsierra_combined <- read_excel(here(\"_posts\", \"post_data\", \"sierra_amphibians.xlsx\")) %>% #read in amphibian excel file\n  filter(amphibian_species == \"RAMU\") %>% #filter by RAMU\n  filter(amphibian_life_stage == \"Adult\" | amphibian_life_stage == \"SubAdult\") %>% #filter data by only adults and subadults\n  group_by(lake_id) %>% #group by lake_id to get counts for each lake_id\n  summarise(n = n()) %>% #put observation of each lake_id in a new column \"n\"\n  mutate(lake_text = paste(\"Lake\",lake_id)) %>% #concatenate \"Lake\" in front of the lake_id values so they are easier for user to read and can be adjusted using fct_reorder\n  slice_max(n, n = 5) %>%  #select lakes with largest observation counts\n  mutate(lake_text = fct_reorder(lake_text, n, .fun = 'max')) #convert values to an ordered factor\n\n#Graph data\ngraph_2 <- ggplot(data = sierra_combined, aes(x = lake_text, y = n)) +\n  geom_col() +\n  labs( \n    title = \"Counts of mountain yellow-legged frogs observed in the 5 lakes with the greatest observed counts\",\n    y = \"Count of amphibian\",\n    x = \"Lake\",\n    cex.main = .25\n  ) +\n  theme_minimal()\n\n\n\nExploratory Findings\n\n\nhide\n\n#generate compound figure\n(graph_1 / graph_2) & theme(plot.title = element_text(size=10))\n\n\n\n\nFigure 1: These figures explore amphibian abundance\ndata recorded by the Sierra Lakes Inventory Project. The top line chart\ngraphs the total mountain yellow-legged frog (Rana muscosa) count each\nyear across all water bodies, by life stage excluding the ‘EggMass’\nlevel. The column graph contains total counts of combined adult and\nsubadult endangered mountain yellow-legged frogs (Rana muscosa) observed\nin the 5 lakes with the greatest total observed counts across all years\nof the study.\nSummary\nThis exploratory data analysis revealed:\nFor most years, counts of mountain yellow-legged frog tadpoles were\nhigher relative to adult and subadult populations across all water\nbodies\nLake 50183 exhibited the largest number of observed counts relative\nto other lakes.\nCitations\nKnapp, R.A., C. Pavelka, E.E. Hegeman, and T.C. Smith. 2020. The\nSierra Lakes Inventory Project: Non-Native fish and community\ncomposition of lakes and ponds in the Sierra Nevada, California ver 2.\nEnvironmental Data Initiative. https://doi.org/10.6073/pasta/d835832d7fd00d9e4466e44eea87fab3\n\n\n\n",
    "preview": "posts/2021-03-13-post2/post2_files/figure-html5/unnamed-chunk-4-1.png",
    "last_modified": "2023-02-21T15:06:32-08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-03-13-post1/",
    "title": "Hierarchical clustering analysis of the Santa Barbara Coastal drainage area watershed by complete linkage",
    "description": "This report performs a hierarchical clustering analysis of Santa Barbara area watersheds by collection site using water chemistry measurements.",
    "author": [
      {
        "name": "Thomas Wheeler",
        "url": {}
      }
    ],
    "date": "2021-03-03",
    "categories": [
      "data-visualization",
      "statistical-analysis"
    ],
    "contents": "\nOverview\nThis report performs a hierarchical clustering analysis of Santa Barbara area watersheds by collection site using water chemistry measurements. To conduct the analysis, averages of all values are calculated for each site, then euclidean distances are calculated for each site (4 of the 13 original sites are dropped due to NA values) before complete linkage agglomerative hierarchical clustering is performed.\nData\nThis data contains stream water chemistry measurements taken in Santa Barbara area watersheds, beginning in 2000. This dataset is ongoing, and data has been added approximately annually. Stream water samples are collected weekly during non-storm flows in winter, and bi-weekly during summer. During winter storms, samples are collected hourly (rising limb) or at 2-4 hour intervals (falling limb). Analytes sampled in the SBC LTER watersheds include dissolved nitrogen (nitrate, ammonium, total dissolved nitrogen); soluble reactive phosphorus (SRP); particulate organic carbon, nitrogen and phosphorus; total suspended sediments; and conductivity.\n\n\nhide\n\n# load data\nsbc_lter <- read_csv(here(\"_posts\", \"post_data\", \"sbc_lter_registered_stream_chemistry.csv\")) %>% \n  na_if(-999) %>% \n  group_by(site_code) %>% \n  summarise(across(3:11, mean, na.rm= TRUE)) %>% \n  drop_na()\n\n# Make sure to take a look at the data:\nView(sbc_lter)\n\n#scale data\nsbc_lter_scaled <- sbc_lter %>% \n  select(2:10) %>% \n  scale()\n\n#change rowname to site_code name\nrownames(sbc_lter_scaled) <- sbc_lter$site_code\n\n\n\n\nhide\n\n#compute dissimilarity values (Euclidean distances):\neuc_lter <- stats::dist(sbc_lter_scaled, method = \"euclidean\")\n\n\nComplete Linkage Dendrogram\n\n\nhide\n\n# Hierarchical clustering (complete linkage)\nlter_complete <- hclust(euc_lter, method = \"complete\" )\n\n# Plot it (base plot):\nplot(lter_complete, cex = 0.6, hang = -1)\n\n\n\nCitation\nSanta Barbara Coastal LTER and J. Melack. 2019. SBC LTER: Land: Stream chemistry in the Santa Barbara Coastal drainage area, ongoing since 2000 ver 16. Environmental Data Initiative. https://doi.org/10.6073/pasta/67a558a24ceed9a0a5bf5e46ab841174.\n\n\n\n",
    "preview": "posts/2021-03-13-post1/post1_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2023-03-10T11:39:21-08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-02-08-welcome/",
    "title": "Spatial Analysis of Oil Spills In California",
    "description": "Mapping spatial data using R.",
    "author": [
      {
        "name": "Thomas Wheeler",
        "url": {}
      }
    ],
    "date": "2021-02-25",
    "categories": [],
    "contents": "\nOverview\nThis project conducts an exploratory analysis of oil spill incidents in California. The first tab is an interactive graph of oil spill locations throughout California and the second visualizes cumulative counties of oil spills by county to better understand which counties are most impacted by oil spills.\nData\nThe Office of Spill Prevention and Response (OSPR) Incident Tracking Database is a statewide oil spill tracking information system. The data are collected by OSPR Field Response Team members for Marine oil spills and by OSPR Inland Pollution Coordinators and Wardens for Inland incidents.\nData source: Office of Spill Prevention and Response (OSPR) Incident Tracking Database CA.gov\nPackages Used in Analysis\n\n\nhide\n\nknitr::opts_chunk$set(echo = TRUE)\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(janitor)\nlibrary(sf)\nlibrary(tmap)\nlibrary(gstat)\nlibrary(stars)\n\n\n\n\nOil Spill Locations in California\nThis interactive map provides an overview of all oil spill locations recorded by the Office of Spill Prevention and Response.\n\n\nhide\n\n#read in California counties layer\nca_counties <- read_sf(here(\"_posts\", \"2021-02-08-welcome\", \"welcome_files\", \"data\"), layer = \"CA_Counties_TIGER2016\") %>%\n  clean_names()\n\n#read in California counties layer\noil_spills <- read_sf(here(\"_posts\", \"2021-02-08-welcome\", \"welcome_files\", \"data\"), layer = \"Oil_Spill_Incident_Tracking_%5Bds394%5D\") %>%\n  clean_names()\n\n\n\n\n\nhide\n\n#make tmap interactive\ntmap_mode(\"view\")\n\n#plot interactive map\ntm_shape(oil_spills) +\n  tm_dots()\n\n\n\n\nCount of Oil Spills by County\nThis static map aggregates all oil spill incidents recorded by county.\n\n\nhide\n\n#join oil_spills with california counties layer\nca_oil_spills <- ca_counties %>% \n  st_join(oil_spills)\n\n#count of values in ca counties\nca_counts <- ca_oil_spills %>% \n  count(name)\n\n#create finalized static cloropleth of count of oil spills by county\nggplot(data = ca_counts) +\n  geom_sf(aes(fill = n), color = \"white\", size = 0.1) +\n  scale_fill_gradientn(colors = c(\"lightgray\",\"orange\",\"red\")) +\n  theme_minimal() +\n  labs(fill = \"Number of oil spills\")\n\n\n\n\n\n\n\n",
    "preview": "posts/2021-02-08-welcome/welcome_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2021-03-13T14:50:27-08:00",
    "input_file": {}
  },
  {
    "path": "posts/2023-03-14-evchargers/",
    "title": "Undergraduate Capstone Consulting Project",
    "description": "Charging the Future: EV Infrastructure Implementation in the City of Santa Clara",
    "author": [
      {
        "name": "Thomas Wheeler",
        "url": {}
      }
    ],
    "date": "2016-04-01",
    "categories": [
      "energy-transition",
      "surveys",
      "consulting"
    ],
    "contents": "\nConsulting project team members\nThomas Wheeler (project manager)Keely O’DonnellMario TapiaBrennan Balson\nFaculty advisor\nStephanie Hughes\nClient\nSilicon Valley Power\nWhat are capstone projects?\nSanta Clara University Environmental Science & Studies students form cross-disciplinary consulting teams and work to address a wide range of environmental issues, with the goal of providing research of value to a community partner or agency. Learn more about capstone projects here.\nFinal poster\nAbstract\nThe current scarcity of electric vehicle (EV) charging stations throughout Silicon Valley continues to constrain commuters and locals seeking affordable, reliable and convenient charging opportunities. In partnership with Silicon Valley Power (SVP), the City of Santa Clara’s (CoSC) publicly owned electric utility and recent recipient of funding to install 8 new chargers, we investigated key considerations to guide strategic installation of new publicly owned charging stations to maximize public benefit. Our methods focused primarily on collecting data from EV owners to understand the relationship between EV owner demographics and their patterns of EV use. Data were collected via internet surveys and structured interviews. Background and guidance for framing our survey questions were acquired via a literature review and are discussed in the introduction and literature review sections of this paper.\nWe found that public chargers are needed to meet a multitude of demand profiles including commuting, leisure activities and errands, and multi-family residences which typically are unable to install chargers in their homes. SVP will need to consider implementing a mix of Level One, Two, and Three chargers to meet this demand and will need to advocate for policy reform to support installation in multi-family residences. Using the findings from our investigation, we provide recommendations for specific placement of the 8 new charging stations to be installed by SVP throughout the City of Santa Clara (CoSC).\nSurvey results and recommended EV charger locations\nFigure 1: Demographic survey results.Figure 2: Patterns of use survey results.Figure 3: Recommended locations for siting EV chargers.\n\n\n",
    "preview": "posts/2023-03-14-evchargers/svp.jpeg",
    "last_modified": "2023-03-14T20:00:09-07:00",
    "input_file": "evchargers.knit.md"
  }
]
